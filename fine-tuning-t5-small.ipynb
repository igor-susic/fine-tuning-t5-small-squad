{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4878ee1-38a2-4ab4-9b1d-9c0a2a1522c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                  Version\n",
      "---------------------------------------- --------------\n",
      "absl-py                                  2.1.0\n",
      "accelerate                               1.0.0\n",
      "aiofiles                                 22.1.0\n",
      "aiohappyeyeballs                         2.4.0\n",
      "aiohttp                                  3.10.5\n",
      "aiohttp-cors                             0.7.0\n",
      "aiosignal                                1.3.1\n",
      "aiosqlite                                0.20.0\n",
      "ansicolors                               1.1.8\n",
      "anyio                                    4.6.0\n",
      "archspec                                 0.2.3\n",
      "argon2-cffi                              23.1.0\n",
      "argon2-cffi-bindings                     21.2.0\n",
      "arrow                                    1.3.0\n",
      "asttokens                                2.4.1\n",
      "async-timeout                            4.0.3\n",
      "atpublic                                 4.1.0\n",
      "attrs                                    24.2.0\n",
      "babel                                    2.16.0\n",
      "backports.tarfile                        1.2.0\n",
      "beatrix_jupyterlab                       2024.920.84202\n",
      "beautifulsoup4                           4.12.3\n",
      "bidict                                   0.23.1\n",
      "bigframes                                1.9.0\n",
      "bleach                                   6.1.0\n",
      "blessed                                  1.20.0\n",
      "boltons                                  24.0.0\n",
      "Brotli                                   1.1.0\n",
      "cachetools                               5.5.0\n",
      "certifi                                  2024.8.30\n",
      "cffi                                     1.17.1\n",
      "charset-normalizer                       3.3.2\n",
      "click                                    8.1.7\n",
      "cloud-tpu-client                         0.10\n",
      "cloudpickle                              3.0.0\n",
      "colorama                                 0.4.6\n",
      "colorful                                 0.5.6\n",
      "comm                                     0.2.2\n",
      "conda                                    24.7.1\n",
      "conda-libmamba-solver                    24.7.0\n",
      "conda-package-handling                   2.3.0\n",
      "conda_package_streaming                  0.10.0\n",
      "contourpy                                1.3.0\n",
      "cryptography                             43.0.1\n",
      "cupy-cuda12x                             13.3.0\n",
      "cycler                                   0.12.1\n",
      "Cython                                   3.0.11\n",
      "dacite                                   1.8.1\n",
      "dataproc_jupyter_plugin                  0.1.74\n",
      "db-dtypes                                1.3.0\n",
      "debugpy                                  1.8.5\n",
      "decorator                                5.1.1\n",
      "defusedxml                               0.7.1\n",
      "Deprecated                               1.2.14\n",
      "distlib                                  0.3.8\n",
      "distro                                   1.9.0\n",
      "dm-tree                                  0.1.8\n",
      "docker                                   7.1.0\n",
      "docstring_parser                         0.16\n",
      "entrypoints                              0.4\n",
      "exceptiongroup                           1.2.2\n",
      "executing                                2.1.0\n",
      "Farama-Notifications                     0.0.4\n",
      "fastapi                                  0.115.0\n",
      "fastjsonschema                           2.20.0\n",
      "fastrlock                                0.8.2\n",
      "filelock                                 3.16.1\n",
      "fonttools                                4.53.1\n",
      "fqdn                                     1.5.1\n",
      "frozendict                               2.4.4\n",
      "frozenlist                               1.4.1\n",
      "fsspec                                   2024.9.0\n",
      "gcsfs                                    2024.9.0.post1\n",
      "geopandas                                1.0.1\n",
      "gitdb                                    4.0.11\n",
      "GitPython                                3.1.43\n",
      "google-api-core                          1.34.1\n",
      "google-api-python-client                 1.8.0\n",
      "google-auth                              2.35.0\n",
      "google-auth-httplib2                     0.2.0\n",
      "google-auth-oauthlib                     1.2.1\n",
      "google-cloud-aiplatform                  1.67.1\n",
      "google-cloud-artifact-registry           1.11.5\n",
      "google-cloud-bigquery                    3.25.0\n",
      "google-cloud-bigquery-connection         1.15.5\n",
      "google-cloud-bigquery-storage            2.26.0\n",
      "google-cloud-core                        2.4.1\n",
      "google-cloud-datastore                   1.15.5\n",
      "google-cloud-functions                   1.17.0\n",
      "google-cloud-iam                         2.15.2\n",
      "google-cloud-jupyter-config              0.0.10\n",
      "google-cloud-language                    2.14.0\n",
      "google-cloud-monitoring                  2.22.2\n",
      "google-cloud-resource-manager            1.12.5\n",
      "google-cloud-storage                     2.14.0\n",
      "google-crc32c                            1.6.0\n",
      "google-resumable-media                   2.7.2\n",
      "googleapis-common-protos                 1.65.0\n",
      "gpustat                                  1.0.0\n",
      "greenlet                                 3.1.1\n",
      "grpc-google-iam-v1                       0.13.1\n",
      "grpcio                                   1.66.1\n",
      "grpcio-status                            1.48.2\n",
      "gymnasium                                0.28.1\n",
      "h11                                      0.14.0\n",
      "h2                                       4.1.0\n",
      "hpack                                    4.0.0\n",
      "htmlmin                                  0.1.12\n",
      "httplib2                                 0.22.0\n",
      "httptools                                0.6.1\n",
      "huggingface-hub                          0.25.1\n",
      "humanize                                 4.10.0\n",
      "hyperframe                               6.0.1\n",
      "ibis-framework                           8.0.0\n",
      "idna                                     3.8\n",
      "ImageHash                                4.3.1\n",
      "imageio                                  2.35.1\n",
      "importlib_metadata                       8.4.0\n",
      "ipykernel                                6.29.5\n",
      "ipython                                  8.21.0\n",
      "ipython-genutils                         0.2.0\n",
      "ipython-sql                              0.5.0\n",
      "ipywidgets                               8.1.5\n",
      "isoduration                              20.11.0\n",
      "jaraco.classes                           3.4.0\n",
      "jaraco.context                           6.0.1\n",
      "jaraco.functools                         4.0.2\n",
      "jax-jumpy                                1.0.0\n",
      "jedi                                     0.19.1\n",
      "jeepney                                  0.8.0\n",
      "jellyfish                                1.1.0\n",
      "Jinja2                                   3.1.4\n",
      "joblib                                   1.4.2\n",
      "json5                                    0.9.25\n",
      "jsonpatch                                1.33\n",
      "jsonpointer                              3.0.0\n",
      "jsonschema                               4.23.0\n",
      "jsonschema-specifications                2023.12.1\n",
      "jupyter_client                           7.4.9\n",
      "jupyter_core                             5.7.2\n",
      "jupyter-events                           0.10.0\n",
      "jupyter-http-over-ws                     0.0.8\n",
      "jupyter_server                           2.14.2\n",
      "jupyter_server_fileid                    0.9.3\n",
      "jupyter-server-mathjax                   0.2.6\n",
      "jupyter_server_proxy                     4.4.0\n",
      "jupyter_server_terminals                 0.5.3\n",
      "jupyter_server_ydoc                      0.8.0\n",
      "jupyter-ydoc                             0.2.5\n",
      "jupyterlab                               3.6.6\n",
      "jupyterlab_git                           0.44.0\n",
      "jupyterlab_pygments                      0.3.0\n",
      "jupyterlab_server                        2.27.3\n",
      "jupyterlab_widgets                       3.0.13\n",
      "jupytext                                 1.16.4\n",
      "kernels-mixer                            0.0.15\n",
      "keyring                                  25.4.1\n",
      "keyrings.google-artifactregistry-auth    1.1.2\n",
      "kfp                                      2.5.0\n",
      "kfp-pipeline-spec                        0.2.2\n",
      "kfp-server-api                           2.0.5\n",
      "kiwisolver                               1.4.7\n",
      "kubernetes                               26.1.0\n",
      "lazy_loader                              0.4\n",
      "libmambapy                               1.5.9\n",
      "linkify-it-py                            2.0.3\n",
      "llvmlite                                 0.41.1\n",
      "lz4                                      4.3.3\n",
      "mamba                                    1.5.9\n",
      "markdown-it-py                           3.0.0\n",
      "MarkupSafe                               2.1.5\n",
      "matplotlib                               3.7.3\n",
      "matplotlib-inline                        0.1.7\n",
      "mdit-py-plugins                          0.4.2\n",
      "mdurl                                    0.1.2\n",
      "memray                                   1.14.0\n",
      "menuinst                                 2.1.2\n",
      "mistune                                  3.0.2\n",
      "more-itertools                           10.5.0\n",
      "mpmath                                   1.3.0\n",
      "msgpack                                  1.1.0\n",
      "multidict                                6.1.0\n",
      "multimethod                              1.12\n",
      "multipledispatch                         1.0.0\n",
      "nbclassic                                1.1.0\n",
      "nbclient                                 0.10.0\n",
      "nbconvert                                7.16.4\n",
      "nbdime                                   3.2.0\n",
      "nbformat                                 5.10.4\n",
      "nest-asyncio                             1.6.0\n",
      "networkx                                 3.3\n",
      "notebook                                 6.5.7\n",
      "notebook_executor                        0.2\n",
      "notebook_shim                            0.2.4\n",
      "numba                                    0.58.1\n",
      "numpy                                    1.25.2\n",
      "nvidia-cublas-cu11                       11.11.3.6\n",
      "nvidia-cuda-cupti-cu11                   11.8.87\n",
      "nvidia-cuda-nvrtc-cu11                   11.8.89\n",
      "nvidia-cuda-runtime-cu11                 11.8.89\n",
      "nvidia-cudnn-cu11                        9.1.0.70\n",
      "nvidia-cufft-cu11                        10.9.0.58\n",
      "nvidia-curand-cu11                       10.3.0.86\n",
      "nvidia-cusolver-cu11                     11.4.1.48\n",
      "nvidia-cusparse-cu11                     11.7.5.86\n",
      "nvidia-ml-py                             11.495.46\n",
      "nvidia-nccl-cu11                         2.20.5\n",
      "nvidia-nvtx-cu11                         11.8.86\n",
      "oauth2client                             4.1.3\n",
      "oauthlib                                 3.2.2\n",
      "opencensus                               0.11.4\n",
      "opencensus-context                       0.1.3\n",
      "opentelemetry-api                        1.27.0\n",
      "opentelemetry-exporter-otlp              1.27.0\n",
      "opentelemetry-exporter-otlp-proto-common 1.27.0\n",
      "opentelemetry-exporter-otlp-proto-grpc   1.27.0\n",
      "opentelemetry-exporter-otlp-proto-http   1.27.0\n",
      "opentelemetry-proto                      1.27.0\n",
      "opentelemetry-sdk                        1.27.0\n",
      "opentelemetry-semantic-conventions       0.48b0\n",
      "overrides                                7.7.0\n",
      "packaging                                24.1\n",
      "pandas                                   2.0.3\n",
      "pandas-profiling                         3.6.6\n",
      "pandocfilters                            1.5.1\n",
      "papermill                                2.6.0\n",
      "parso                                    0.8.4\n",
      "parsy                                    2.1\n",
      "patsy                                    0.5.6\n",
      "pendulum                                 3.0.0\n",
      "pexpect                                  4.9.0\n",
      "phik                                     0.12.4\n",
      "pillow                                   10.4.0\n",
      "pip                                      24.2\n",
      "platformdirs                             4.2.2\n",
      "plotly                                   5.24.1\n",
      "pluggy                                   1.5.0\n",
      "prettytable                              3.11.0\n",
      "prometheus_client                        0.21.0\n",
      "prompt_toolkit                           3.0.47\n",
      "proto-plus                               1.24.0\n",
      "protobuf                                 3.20.3\n",
      "psutil                                   5.9.3\n",
      "ptyprocess                               0.7.0\n",
      "pure_eval                                0.2.3\n",
      "py-spy                                   0.3.14\n",
      "pyarrow                                  15.0.2\n",
      "pyarrow-hotfix                           0.6\n",
      "pyasn1                                   0.6.1\n",
      "pyasn1_modules                           0.4.1\n",
      "pycosat                                  0.6.6\n",
      "pycparser                                2.22\n",
      "pydantic                                 1.10.18\n",
      "pydata-google-auth                       1.8.2\n",
      "Pygments                                 2.18.0\n",
      "PyJWT                                    2.9.0\n",
      "pyogrio                                  0.9.0\n",
      "pyparsing                                3.1.4\n",
      "pyproj                                   3.6.1\n",
      "PySocks                                  1.7.1\n",
      "python-dateutil                          2.9.0.post0\n",
      "python-dotenv                            1.0.1\n",
      "python-json-logger                       2.0.7\n",
      "pytz                                     2024.2\n",
      "PyWavelets                               1.7.0\n",
      "PyYAML                                   6.0.2\n",
      "pyzmq                                    26.2.0\n",
      "ray                                      2.36.0\n",
      "referencing                              0.35.1\n",
      "regex                                    2024.9.11\n",
      "requests                                 2.32.3\n",
      "requests-oauthlib                        2.0.0\n",
      "requests-toolbelt                        0.10.1\n",
      "retrying                                 1.3.4\n",
      "rfc3339-validator                        0.1.4\n",
      "rfc3986-validator                        0.1.1\n",
      "rich                                     13.8.1\n",
      "rpds-py                                  0.20.0\n",
      "rsa                                      4.9\n",
      "ruamel.yaml                              0.18.6\n",
      "ruamel.yaml.clib                         0.2.8\n",
      "safetensors                              0.4.5\n",
      "scikit-image                             0.24.0\n",
      "scikit-learn                             1.5.2\n",
      "scipy                                    1.11.4\n",
      "seaborn                                  0.12.2\n",
      "SecretStorage                            3.3.3\n",
      "Send2Trash                               1.8.3\n",
      "sentencepiece                            0.2.0\n",
      "setuptools                               73.0.1\n",
      "shapely                                  2.0.6\n",
      "shellingham                              1.5.4\n",
      "simpervisor                              1.0.0\n",
      "six                                      1.16.0\n",
      "smart-open                               7.0.4\n",
      "smmap                                    5.0.1\n",
      "sniffio                                  1.3.1\n",
      "soupsieve                                2.6\n",
      "SQLAlchemy                               2.0.35\n",
      "sqlglot                                  20.11.0\n",
      "sqlparse                                 0.5.1\n",
      "stack-data                               0.6.3\n",
      "starlette                                0.38.6\n",
      "statsmodels                              0.14.3\n",
      "sympy                                    1.12\n",
      "tabulate                                 0.9.0\n",
      "tangled-up-in-unicode                    0.2.0\n",
      "tenacity                                 9.0.0\n",
      "tensorboardX                             2.6.2.2\n",
      "terminado                                0.18.1\n",
      "textual                                  0.79.1\n",
      "threadpoolctl                            3.5.0\n",
      "tifffile                                 2024.9.20\n",
      "time-machine                             2.15.0\n",
      "tinycss2                                 1.3.0\n",
      "tokenizers                               0.20.0\n",
      "tomli                                    2.0.1\n",
      "toolz                                    0.12.1\n",
      "torch                                    2.4.1+cu118\n",
      "torchaudio                               2.4.1+cu118\n",
      "torchvision                              0.19.1+cu118\n",
      "tornado                                  6.4.1\n",
      "tqdm                                     4.66.5\n",
      "traitlets                                5.14.3\n",
      "transformers                             4.45.1\n",
      "triton                                   3.0.0\n",
      "truststore                               0.9.2\n",
      "typeguard                                4.3.0\n",
      "typer                                    0.12.5\n",
      "types-python-dateutil                    2.9.0.20240906\n",
      "typing_extensions                        4.12.2\n",
      "tzdata                                   2024.1\n",
      "uc-micro-py                              1.0.3\n",
      "uri-template                             1.3.0\n",
      "uritemplate                              3.0.1\n",
      "urllib3                                  1.26.20\n",
      "uvicorn                                  0.30.6\n",
      "uvloop                                   0.20.0\n",
      "virtualenv                               20.26.5\n",
      "visions                                  0.7.5\n",
      "watchfiles                               0.24.0\n",
      "wcwidth                                  0.2.13\n",
      "webcolors                                24.8.0\n",
      "webencodings                             0.5.1\n",
      "websocket-client                         1.8.0\n",
      "websockets                               13.1\n",
      "wheel                                    0.44.0\n",
      "widgetsnbextension                       4.0.13\n",
      "wordcloud                                1.9.3\n",
      "wrapt                                    1.16.0\n",
      "y-py                                     0.6.2\n",
      "yarl                                     1.11.1\n",
      "ydata-profiling                          4.6.0\n",
      "ypy-websocket                            0.8.4\n",
      "zipp                                     3.20.2\n",
      "zstandard                                0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce1bf20-f03c-4829-aa27-70327592d668",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.1+cu118)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.1+cu118)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.4.1+cu118)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /opt/conda/lib/python3.10/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /opt/conda/lib/python3.10/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /opt/conda/lib/python3.10/site-packages (from torch) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /opt/conda/lib/python3.10/site-packages (from torch) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /opt/conda/lib/python3.10/site-packages (from torch) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /opt/conda/lib/python3.10/site-packages (from torch) (11.8.86)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.25.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "129680ce-da0e-4578-9d01-2dc5ab6729c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee4b76b-5a87-4051-a834-27c7e2220e1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0) (2.4.1+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0) (0.25.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0) (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.9.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.8.86)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.26.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.8.30)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate>=0.26.0) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d047f6d3-530c-47fa-8ba5-3adaef505ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e487fff-2899-427a-aacb-25c7bb4919e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab751a4-da77-426c-a321-3a63f6378150",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Pytorch: 2.4.1+cu118\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running Pytorch: {torch.__version__}\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"This notebook was writen to be executed by a GPU!\")\n",
    "    \n",
    "# I know that I have only one GPU on this system so will map it to the first one\n",
    "DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b644fad-2713-4862-a943-c060bc0d768c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct  9 04:35:33 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   70C    P8             12W /   70W |       3MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09a1b03e-e88a-4e7d-9bd9-970c489dfdcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import json\n",
    "import transformers\n",
    "from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba0d335-e875-4492-bf9f-2c2a4a4f02c0",
   "metadata": {},
   "source": [
    "# Model choosen\n",
    "\n",
    "![alt text](./assets/t5-diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3df891-1d4c-40f5-b4e4-e02f7ae72be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_used = \"google-t5/t5-small\"\n",
    "\n",
    "# We want to map immidiatley the model onto the GPU\n",
    "model = T5ForConditionalGeneration.from_pretrained(pretrained_model_used, device_map=DEVICE, torch_dtype=\"auto\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(pretrained_model_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6ede06b-a4b5-4544-a8dc-28a5f3677530",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct  9 04:35:36 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   71C    P0             30W /   70W |     341MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A    246581      C   /opt/conda/bin/python                         338MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi # check how much memory model consumed on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc9334b-031c-427c-a58c-e57b27d03e04",
   "metadata": {},
   "source": [
    "# Dataset loading and tokenization\n",
    "\n",
    "It is important we follow the same instructions from the paper, because othervise we would not finetune the model right.\n",
    "\n",
    "![alt text](./assets/input-out-format.png)\n",
    "\n",
    "Example of how the SQuAD dataset should be prepared for fine-tuning.\n",
    "\n",
    "![alt text](./assets/squad-first-pt.png)\n",
    "![alt text](./assets/squad-second-pt.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1804256b-2cc0-45bd-9f6d-d942af519442",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SQuADDataset:\n",
    "    def __init__(self, ids, questions, contexts, answers) -> None:\n",
    "        self.ids = ids\n",
    "        self.questions = questions\n",
    "        self.contexts = contexts\n",
    "        self.answers = answers\n",
    "        \n",
    "    def tokenize_input(self) -> dict:\n",
    "        \"\"\"\n",
    "        Tokenizer will add EOS tokens at the end of the sentence and in between so it will look like:\n",
    "        question: .... </s> context: .... </s>\n",
    "        \n",
    "        Also anything shorter will be padded with <pad> token\n",
    "        \"\"\"\n",
    "        return tokenizer(self.questions, self.contexts, padding='max_length', truncation='only_second', max_length=512, return_tensors=\"pt\")\n",
    "    \n",
    "    def tokenize_target(self) -> dict:\n",
    "        return tokenizer(self.answers, padding='max_length', truncation=True, max_length=24, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08d46ce1-6bcd-47ac-8d98-63baf2de161b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset_and_preprocess(path: str) -> SQuADDataset:\n",
    "    fp = open(path)\n",
    "    dataset: dict = json.load(fp)\n",
    "    fp.close()\n",
    "    \n",
    "    print(f\"Loading dataset SQuAD version: {dataset['version']}\")\n",
    "    \n",
    "    data: list = dataset.get(\"data\")\n",
    "    \n",
    "    ids = []\n",
    "    questions = []\n",
    "    contexts = []\n",
    "    answers = []\n",
    "    \n",
    "    for chunk in data:\n",
    "        print(f\"Loading paragraph: {chunk.get('title')}\")\n",
    "        \n",
    "        paragraphs: list[dict] = chunk.get(\"paragraphs\")\n",
    "        \n",
    "        for paragraph in paragraphs:\n",
    "            qas = paragraph.get(\"qas\")\n",
    "            context = paragraph.get(\"context\")\n",
    "            \n",
    "            for example in qas:\n",
    "                question = example.get(\"question\")\n",
    "                q_id = example.get(\"id\")\n",
    "                \n",
    "                # We will take only one answer example\n",
    "                list_of_answers = example.get(\"answers\")\n",
    "                answer = list_of_answers[0].get(\"text\") if len(list_of_answers) > 0 else \"\"\n",
    "                \n",
    "                q = f\"question: {question}\"\n",
    "                ctx = f\"context: {context}\"\n",
    "                \n",
    "                ids.append(q_id)\n",
    "                questions.append(q)\n",
    "                contexts.append(ctx)\n",
    "                answers.append(answer)\n",
    "                \n",
    "    return SQuADDataset(ids, questions, contexts, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78e52fb4-863a-4b6f-bf47-9c53cef7829b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset SQuAD version: v2.0\n",
      "Loading paragraph: Beyoncé\n",
      "Loading paragraph: Frédéric_Chopin\n",
      "Loading paragraph: Sino-Tibetan_relations_during_the_Ming_dynasty\n",
      "Loading paragraph: IPod\n",
      "Loading paragraph: The_Legend_of_Zelda:_Twilight_Princess\n",
      "Loading paragraph: Spectre_(2015_film)\n",
      "Loading paragraph: 2008_Sichuan_earthquake\n",
      "Loading paragraph: New_York_City\n",
      "Loading paragraph: To_Kill_a_Mockingbird\n",
      "Loading paragraph: Solar_energy\n",
      "Loading paragraph: Kanye_West\n",
      "Loading paragraph: Buddhism\n",
      "Loading paragraph: American_Idol\n",
      "Loading paragraph: Dog\n",
      "Loading paragraph: 2008_Summer_Olympics_torch_relay\n",
      "Loading paragraph: Genome\n",
      "Loading paragraph: Comprehensive_school\n",
      "Loading paragraph: Republic_of_the_Congo\n",
      "Loading paragraph: Prime_minister\n",
      "Loading paragraph: Institute_of_technology\n",
      "Loading paragraph: Wayback_Machine\n",
      "Loading paragraph: Dutch_Republic\n",
      "Loading paragraph: Symbiosis\n",
      "Loading paragraph: Canadian_Armed_Forces\n",
      "Loading paragraph: Cardinal_(Catholicism)\n",
      "Loading paragraph: Iranian_languages\n",
      "Loading paragraph: Lighting\n",
      "Loading paragraph: Separation_of_powers_under_the_United_States_Constitution\n",
      "Loading paragraph: Architecture\n",
      "Loading paragraph: Human_Development_Index\n",
      "Loading paragraph: Southern_Europe\n",
      "Loading paragraph: BBC_Television\n",
      "Loading paragraph: Arnold_Schwarzenegger\n",
      "Loading paragraph: Plymouth\n",
      "Loading paragraph: Heresy\n",
      "Loading paragraph: Warsaw_Pact\n",
      "Loading paragraph: Materialism\n",
      "Loading paragraph: Christian\n",
      "Loading paragraph: Sony_Music_Entertainment\n",
      "Loading paragraph: Oklahoma_City\n",
      "Loading paragraph: Hunter-gatherer\n",
      "Loading paragraph: United_Nations_Population_Fund\n",
      "Loading paragraph: Russian_Soviet_Federative_Socialist_Republic\n",
      "Loading paragraph: Alexander_Graham_Bell\n",
      "Loading paragraph: Pub\n",
      "Loading paragraph: Internet_service_provider\n",
      "Loading paragraph: Comics\n",
      "Loading paragraph: Saint_Helena\n",
      "Loading paragraph: Aspirated_consonant\n",
      "Loading paragraph: Hydrogen\n",
      "Loading paragraph: Space_Race\n",
      "Loading paragraph: Web_browser\n",
      "Loading paragraph: BeiDou_Navigation_Satellite_System\n",
      "Loading paragraph: Canon_law\n",
      "Loading paragraph: Communications_in_Somalia\n",
      "Loading paragraph: Catalan_language\n",
      "Loading paragraph: Boston\n",
      "Loading paragraph: Universal_Studios\n",
      "Loading paragraph: Estonian_language\n",
      "Loading paragraph: Paper\n",
      "Loading paragraph: Adult_contemporary_music\n",
      "Loading paragraph: Daylight_saving_time\n",
      "Loading paragraph: Royal_Institute_of_British_Architects\n",
      "Loading paragraph: National_Archives_and_Records_Administration\n",
      "Loading paragraph: Tristan_da_Cunha\n",
      "Loading paragraph: University_of_Kansas\n",
      "Loading paragraph: Nanjing\n",
      "Loading paragraph: Arena_Football_League\n",
      "Loading paragraph: Dialect\n",
      "Loading paragraph: Bern\n",
      "Loading paragraph: Westminster_Abbey\n",
      "Loading paragraph: Political_corruption\n",
      "Loading paragraph: Classical_music\n",
      "Loading paragraph: Slavs\n",
      "Loading paragraph: Southampton\n",
      "Loading paragraph: Treaty\n",
      "Loading paragraph: Josip_Broz_Tito\n",
      "Loading paragraph: Marshall_Islands\n",
      "Loading paragraph: Szlachta\n",
      "Loading paragraph: Virgil\n",
      "Loading paragraph: Alps\n",
      "Loading paragraph: Gene\n",
      "Loading paragraph: Guinea-Bissau\n",
      "Loading paragraph: List_of_numbered_streets_in_Manhattan\n",
      "Loading paragraph: Brain\n",
      "Loading paragraph: Near_East\n",
      "Loading paragraph: Zhejiang\n",
      "Loading paragraph: Ministry_of_Defence_(United_Kingdom)\n",
      "Loading paragraph: High-definition_television\n",
      "Loading paragraph: Wood\n",
      "Loading paragraph: Somalis\n",
      "Loading paragraph: Middle_Ages\n",
      "Loading paragraph: Phonology\n",
      "Loading paragraph: Computer\n",
      "Loading paragraph: Black_people\n",
      "Loading paragraph: The_Times\n",
      "Loading paragraph: New_Delhi\n",
      "Loading paragraph: Bird_migration\n",
      "Loading paragraph: Atlantic_City,_New_Jersey\n",
      "Loading paragraph: Immunology\n",
      "Loading paragraph: MP3\n",
      "Loading paragraph: House_music\n",
      "Loading paragraph: Letter_case\n",
      "Loading paragraph: Chihuahua_(state)\n",
      "Loading paragraph: Imamah_(Shia_doctrine)\n",
      "Loading paragraph: Pitch_(music)\n",
      "Loading paragraph: England_national_football_team\n",
      "Loading paragraph: Houston\n",
      "Loading paragraph: Copper\n",
      "Loading paragraph: Identity_(social_science)\n",
      "Loading paragraph: Himachal_Pradesh\n",
      "Loading paragraph: Communication\n",
      "Loading paragraph: Grape\n",
      "Loading paragraph: Computer_security\n",
      "Loading paragraph: Orthodox_Judaism\n",
      "Loading paragraph: Animal\n",
      "Loading paragraph: Beer\n",
      "Loading paragraph: Race_and_ethnicity_in_the_United_States_Census\n",
      "Loading paragraph: United_States_dollar\n",
      "Loading paragraph: Imperial_College_London\n",
      "Loading paragraph: Hanover\n",
      "Loading paragraph: Emotion\n",
      "Loading paragraph: Everton_F.C.\n",
      "Loading paragraph: Old_English\n",
      "Loading paragraph: Aircraft_carrier\n",
      "Loading paragraph: Federal_Aviation_Administration\n",
      "Loading paragraph: Lancashire\n",
      "Loading paragraph: Mesozoic\n",
      "Loading paragraph: Videoconferencing\n",
      "Loading paragraph: Gregorian_calendar\n",
      "Loading paragraph: Xbox_360\n",
      "Loading paragraph: Military_history_of_the_United_States\n",
      "Loading paragraph: Hard_rock\n",
      "Loading paragraph: Great_Plains\n",
      "Loading paragraph: Infrared\n",
      "Loading paragraph: Biodiversity\n",
      "Loading paragraph: ASCII\n",
      "Loading paragraph: Digestion\n",
      "Loading paragraph: Gymnastics\n",
      "Loading paragraph: FC_Barcelona\n",
      "Loading paragraph: Federal_Bureau_of_Investigation\n",
      "Loading paragraph: Mary_(mother_of_Jesus)\n",
      "Loading paragraph: Melbourne\n",
      "Loading paragraph: John,_King_of_England\n",
      "Loading paragraph: Macintosh\n",
      "Loading paragraph: Anti-aircraft_warfare\n",
      "Loading paragraph: Sanskrit\n",
      "Loading paragraph: Valencia\n",
      "Loading paragraph: General_Electric\n",
      "Loading paragraph: United_States_Army\n",
      "Loading paragraph: Franco-Prussian_War\n",
      "Loading paragraph: Adolescence\n",
      "Loading paragraph: Antarctica\n",
      "Loading paragraph: Eritrea\n",
      "Loading paragraph: Uranium\n",
      "Loading paragraph: Order_of_the_British_Empire\n",
      "Loading paragraph: Circadian_rhythm\n",
      "Loading paragraph: Elizabeth_II\n",
      "Loading paragraph: Sexual_orientation\n",
      "Loading paragraph: Dell\n",
      "Loading paragraph: Capital_punishment_in_the_United_States\n",
      "Loading paragraph: Age_of_Enlightenment\n",
      "Loading paragraph: Nintendo_Entertainment_System\n",
      "Loading paragraph: Athanasius_of_Alexandria\n",
      "Loading paragraph: Seattle\n",
      "Loading paragraph: Memory\n",
      "Loading paragraph: Multiracial_American\n",
      "Loading paragraph: Ashkenazi_Jews\n",
      "Loading paragraph: Pharmaceutical_industry\n",
      "Loading paragraph: Umayyad_Caliphate\n",
      "Loading paragraph: Asphalt\n",
      "Loading paragraph: Queen_Victoria\n",
      "Loading paragraph: Freemasonry\n",
      "Loading paragraph: Israel\n",
      "Loading paragraph: Hellenistic_period\n",
      "Loading paragraph: Bill_%26_Melinda_Gates_Foundation\n",
      "Loading paragraph: Montevideo\n",
      "Loading paragraph: Poultry\n",
      "Loading paragraph: Dutch_language\n",
      "Loading paragraph: Buckingham_Palace\n",
      "Loading paragraph: Incandescent_light_bulb\n",
      "Loading paragraph: Arsenal_F.C.\n",
      "Loading paragraph: Clothing\n",
      "Loading paragraph: Chicago_Cubs\n",
      "Loading paragraph: Korean_War\n",
      "Loading paragraph: Copyright_infringement\n",
      "Loading paragraph: Greece\n",
      "Loading paragraph: Royal_Dutch_Shell\n",
      "Loading paragraph: Mammal\n",
      "Loading paragraph: East_India_Company\n",
      "Loading paragraph: Hokkien\n",
      "Loading paragraph: Professional_wrestling\n",
      "Loading paragraph: Film_speed\n",
      "Loading paragraph: Mexico_City\n",
      "Loading paragraph: Napoleon\n",
      "Loading paragraph: Germans\n",
      "Loading paragraph: Southeast_Asia\n",
      "Loading paragraph: Brigham_Young_University\n",
      "Loading paragraph: Department_store\n",
      "Loading paragraph: Intellectual_property\n",
      "Loading paragraph: Florida\n",
      "Loading paragraph: Queen_(band)\n",
      "Loading paragraph: Presbyterianism\n",
      "Loading paragraph: Thuringia\n",
      "Loading paragraph: Predation\n",
      "Loading paragraph: Marvel_Comics\n",
      "Loading paragraph: British_Empire\n",
      "Loading paragraph: Botany\n",
      "Loading paragraph: Madonna_(entertainer)\n",
      "Loading paragraph: Law_of_the_United_States\n",
      "Loading paragraph: Myanmar\n",
      "Loading paragraph: Jews\n",
      "Loading paragraph: Cotton\n",
      "Loading paragraph: Data_compression\n",
      "Loading paragraph: The_Sun_(United_Kingdom)\n",
      "Loading paragraph: Pesticide\n",
      "Loading paragraph: Somerset\n",
      "Loading paragraph: Yale_University\n",
      "Loading paragraph: Late_Middle_Ages\n",
      "Loading paragraph: Ann_Arbor,_Michigan\n",
      "Loading paragraph: Gothic_architecture\n",
      "Loading paragraph: Cubism\n",
      "Loading paragraph: Political_philosophy\n",
      "Loading paragraph: Alloy\n",
      "Loading paragraph: Norfolk_Island\n",
      "Loading paragraph: Edmund_Burke\n",
      "Loading paragraph: Samoa\n",
      "Loading paragraph: Pope_Paul_VI\n",
      "Loading paragraph: Electric_motor\n",
      "Loading paragraph: Switzerland\n",
      "Loading paragraph: Mali\n",
      "Loading paragraph: Raleigh,_North_Carolina\n",
      "Loading paragraph: Nutrition\n",
      "Loading paragraph: Crimean_War\n",
      "Loading paragraph: Nonprofit_organization\n",
      "Loading paragraph: Literature\n",
      "Loading paragraph: Avicenna\n",
      "Loading paragraph: Chinese_characters\n",
      "Loading paragraph: Bermuda\n",
      "Loading paragraph: Nigeria\n",
      "Loading paragraph: Utrecht\n",
      "Loading paragraph: Molotov%E2%80%93Ribbentrop_Pact\n",
      "Loading paragraph: Capacitor\n",
      "Loading paragraph: History_of_science\n",
      "Loading paragraph: Digimon\n",
      "Loading paragraph: Glacier\n",
      "Loading paragraph: Comcast\n",
      "Loading paragraph: Tuberculosis\n",
      "Loading paragraph: Affirmative_action_in_the_United_States\n",
      "Loading paragraph: FA_Cup\n",
      "Loading paragraph: New_Haven,_Connecticut\n",
      "Loading paragraph: Alsace\n",
      "Loading paragraph: Carnival\n",
      "Loading paragraph: Baptists\n",
      "Loading paragraph: Child_labour\n",
      "Loading paragraph: North_Carolina\n",
      "Loading paragraph: Heian_period\n",
      "Loading paragraph: On_the_Origin_of_Species\n",
      "Loading paragraph: Dissolution_of_the_Soviet_Union\n",
      "Loading paragraph: Crucifixion_of_Jesus\n",
      "Loading paragraph: Supreme_court\n",
      "Loading paragraph: Textual_criticism\n",
      "Loading paragraph: Gramophone_record\n",
      "Loading paragraph: Turner_Classic_Movies\n",
      "Loading paragraph: Hindu_philosophy\n",
      "Loading paragraph: Political_party\n",
      "Loading paragraph: A_cappella\n",
      "Loading paragraph: Dominican_Order\n",
      "Loading paragraph: Eton_College\n",
      "Loading paragraph: Cork_(city)\n",
      "Loading paragraph: Galicia_(Spain)\n",
      "Loading paragraph: USB\n",
      "Loading paragraph: Sichuan\n",
      "Loading paragraph: Unicode\n",
      "Loading paragraph: Detroit\n",
      "Loading paragraph: London\n",
      "Loading paragraph: Culture\n",
      "Loading paragraph: Sahara\n",
      "Loading paragraph: Rule_of_law\n",
      "Loading paragraph: Tibet\n",
      "Loading paragraph: Exhibition_game\n",
      "Loading paragraph: Northwestern_University\n",
      "Loading paragraph: Strasbourg\n",
      "Loading paragraph: Oklahoma\n",
      "Loading paragraph: History_of_India\n",
      "Loading paragraph: Gamal_Abdel_Nasser\n",
      "Loading paragraph: Pope_John_XXIII\n",
      "Loading paragraph: Time\n",
      "Loading paragraph: European_Central_Bank\n",
      "Loading paragraph: St._John%27s,_Newfoundland_and_Labrador\n",
      "Loading paragraph: John_von_Neumann\n",
      "Loading paragraph: PlayStation_3\n",
      "Loading paragraph: Royal_assent\n",
      "Loading paragraph: Group_(mathematics)\n",
      "Loading paragraph: Central_African_Republic\n",
      "Loading paragraph: Asthma\n",
      "Loading paragraph: LaserDisc\n",
      "Loading paragraph: George_VI\n",
      "Loading paragraph: Federalism\n",
      "Loading paragraph: Annelid\n",
      "Loading paragraph: God\n",
      "Loading paragraph: War_on_Terror\n",
      "Loading paragraph: Labour_Party_(UK)\n",
      "Loading paragraph: Estonia\n",
      "Loading paragraph: Alaska\n",
      "Loading paragraph: Karl_Popper\n",
      "Loading paragraph: Mandolin\n",
      "Loading paragraph: Insect\n",
      "Loading paragraph: Race_(human_categorization)\n",
      "Loading paragraph: Paris\n",
      "Loading paragraph: Apollo\n",
      "Loading paragraph: United_States_presidential_election,_2004\n",
      "Loading paragraph: Liberal_Party_of_Australia\n",
      "Loading paragraph: Samurai\n",
      "Loading paragraph: Software_testing\n",
      "Loading paragraph: States_of_Germany\n",
      "Loading paragraph: Glass\n",
      "Loading paragraph: Planck_constant\n",
      "Loading paragraph: Renewable_energy_commercialization\n",
      "Loading paragraph: Palermo\n",
      "Loading paragraph: Green\n",
      "Loading paragraph: Zinc\n",
      "Loading paragraph: Neoclassical_architecture\n",
      "Loading paragraph: Serbo-Croatian\n",
      "Loading paragraph: CBC_Television\n",
      "Loading paragraph: Appalachian_Mountains\n",
      "Loading paragraph: IBM\n",
      "Loading paragraph: Energy\n",
      "Loading paragraph: East_Prussia\n",
      "Loading paragraph: Ottoman_Empire\n",
      "Loading paragraph: Philosophy_of_space_and_time\n",
      "Loading paragraph: Neolithic\n",
      "Loading paragraph: Friedrich_Hayek\n",
      "Loading paragraph: Diarrhea\n",
      "Loading paragraph: Madrasa\n",
      "Loading paragraph: Miami\n",
      "Loading paragraph: Philadelphia\n",
      "Loading paragraph: John_Kerry\n",
      "Loading paragraph: Rajasthan\n",
      "Loading paragraph: Guam\n",
      "Loading paragraph: Empiricism\n",
      "Loading paragraph: Idealism\n",
      "Loading paragraph: Czech_language\n",
      "Loading paragraph: Education\n",
      "Loading paragraph: Tennessee\n",
      "Loading paragraph: Post-punk\n",
      "Loading paragraph: Canadian_football\n",
      "Loading paragraph: Seven_Years%27_War\n",
      "Loading paragraph: Richard_Feynman\n",
      "Loading paragraph: Muammar_Gaddafi\n",
      "Loading paragraph: Cyprus\n",
      "Loading paragraph: Steven_Spielberg\n",
      "Loading paragraph: Elevator\n",
      "Loading paragraph: Neptune\n",
      "Loading paragraph: Railway_electrification_system\n",
      "Loading paragraph: Spanish_language_in_the_United_States\n",
      "Loading paragraph: Charleston,_South_Carolina\n",
      "Loading paragraph: The_Blitz\n",
      "Loading paragraph: Endangered_Species_Act\n",
      "Loading paragraph: Vacuum\n",
      "Loading paragraph: Han_dynasty\n",
      "Loading paragraph: Quran\n",
      "Loading paragraph: Geography_of_the_United_States\n",
      "Loading paragraph: Compact_disc\n",
      "Loading paragraph: Transistor\n",
      "Loading paragraph: Modern_history\n",
      "Loading paragraph: 51st_state\n",
      "Loading paragraph: Antenna_(radio)\n",
      "Loading paragraph: Flowering_plant\n",
      "Loading paragraph: Hyderabad\n",
      "Loading paragraph: Santa_Monica,_California\n",
      "Loading paragraph: Washington_University_in_St._Louis\n",
      "Loading paragraph: Central_Intelligence_Agency\n",
      "Loading paragraph: Pain\n",
      "Loading paragraph: Database\n",
      "Loading paragraph: Tucson,_Arizona\n",
      "Loading paragraph: Armenia\n",
      "Loading paragraph: Bacteria\n",
      "Loading paragraph: Printed_circuit_board\n",
      "Loading paragraph: Greeks\n",
      "Loading paragraph: Premier_League\n",
      "Loading paragraph: Roman_Republic\n",
      "Loading paragraph: Pacific_War\n",
      "Loading paragraph: San_Diego\n",
      "Loading paragraph: Muslim_world\n",
      "Loading paragraph: Iran\n",
      "Loading paragraph: British_Isles\n",
      "Loading paragraph: Association_football\n",
      "Loading paragraph: Georgian_architecture\n",
      "Loading paragraph: Liberia\n",
      "Loading paragraph: Alfred_North_Whitehead\n",
      "Loading paragraph: Antibiotics\n",
      "Loading paragraph: Windows_8\n",
      "Loading paragraph: Swaziland\n",
      "Loading paragraph: Translation\n",
      "Loading paragraph: Airport\n",
      "Loading paragraph: Kievan_Rus%27\n",
      "Loading paragraph: Super_Nintendo_Entertainment_System\n",
      "Loading paragraph: Sumer\n",
      "Loading paragraph: Tuvalu\n",
      "Loading paragraph: Immaculate_Conception\n",
      "Loading paragraph: Namibia\n",
      "Loading paragraph: Russian_language\n",
      "Loading paragraph: United_States_Air_Force\n",
      "Loading paragraph: Light-emitting_diode\n",
      "Loading paragraph: Great_power\n",
      "Loading paragraph: Bird\n",
      "Loading paragraph: Qing_dynasty\n",
      "Loading paragraph: Indigenous_peoples_of_the_Americas\n",
      "Loading paragraph: Red\n",
      "Loading paragraph: Egypt\n",
      "Loading paragraph: Mosaic\n",
      "Loading paragraph: University\n",
      "Loading paragraph: Religion_in_ancient_Rome\n",
      "Loading paragraph: YouTube\n",
      "Loading paragraph: Separation_of_church_and_state_in_the_United_States\n",
      "Loading paragraph: Protestantism\n",
      "Loading paragraph: Bras%C3%ADlia\n",
      "Loading paragraph: Economy_of_Greece\n",
      "Loading paragraph: Party_leaders_of_the_United_States_House_of_Representatives\n",
      "Loading paragraph: Armenians\n",
      "Loading paragraph: Jehovah%27s_Witnesses\n",
      "Loading paragraph: Dwight_D._Eisenhower\n",
      "Loading paragraph: The_Bronx\n",
      "Loading paragraph: Financial_crisis_of_2007%E2%80%9308\n",
      "Loading paragraph: Portugal\n",
      "Loading paragraph: Humanism\n",
      "Loading paragraph: Geological_history_of_Earth\n",
      "Loading paragraph: Police\n",
      "Loading paragraph: Genocide\n",
      "Loading paragraph: Saint_Barth%C3%A9lemy\n",
      "Loading paragraph: Tajikistan\n",
      "Loading paragraph: University_of_Notre_Dame\n",
      "Loading paragraph: Anthropology\n",
      "Loading paragraph: Montana\n",
      "Loading paragraph: Punjab,_Pakistan\n",
      "Loading paragraph: Richmond,_Virginia\n",
      "Loading paragraph: Infection\n",
      "Loading paragraph: Hunting\n",
      "Loading paragraph: Kathmandu\n",
      "Loading paragraph: Myocardial_infarction\n",
      "Loading paragraph: Matter\n"
     ]
    }
   ],
   "source": [
    "ds: SQuADDataset = load_dataset_and_preprocess(\"./train-v2.0.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a1fe4f1-9145-4626-9581-79bfed045938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_input = ds.tokenize_input()\n",
    "tokenized_target = ds.tokenize_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f285829-0995-4f2d-9064-b0a9249aa807",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question: In what city and state did Beyonce grow up?</s> context: Beyoncé Giselle Knowles-Carter (/bi<unk> j<unk> nse<unk> / bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check one input example\n",
    "tokenizer.decode(tokenized_input[\"input_ids\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "150af6f3-d18e-46ed-82b9-a459ffc03bab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Houston, Texas</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check target pair for the above example\n",
    "tokenizer.decode(tokenized_target[\"input_ids\"][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1948482-c949-4b70-bc7b-9b81f5488df0",
   "metadata": {},
   "source": [
    "# Fine tunning the model\n",
    "\n",
    "![alt text](./assets/training.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5cc59ae-b1e4-4c79-8858-7dbbc39b4d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d279d90d-d29a-4c1f-8cd5-f45270c2c0da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(tokenized_input.get(\"input_ids\"), tokenized_input.get(\"attention_mask\"), tokenized_target.get(\"input_ids\"), tokenized_target.get(\"attention_mask\")) # Order of these parameters is same later once we read it\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12e51775-09f2-4b35-bfd1-b6cfed332fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers.optimization import Adafactor # As was used in the original paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69e6a597-4531-4d43-bc52-b3298dd241a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = Adafactor(model.parameters(), scale_parameter=False, relative_step=False, warmup_init=False, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fd2e53c-085f-4e28-a30f-8f19a8b14800",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct  9 04:37:40 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   74C    P0             31W /   70W |     341MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A    246581      C   /opt/conda/bin/python                         338MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bacd2615-bf6f-4019-a020-f10ab9202280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fine_tune_t5(epochs: int):\n",
    "    model.train(True) # Set model into training mode\n",
    "    step = 0\n",
    "    running_loss = 0.\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"EPOCH - {epoch}\")\n",
    "        for data in train_dataloader:\n",
    "            input_ids: torch.Tensor\n",
    "            input_att_mask: torch.Tensor\n",
    "            target_ids: torch.Tensor\n",
    "            target_att_mask: torch.Tensor\n",
    "\n",
    "            input_ids, input_att_mask, target_ids, target_att_mask = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = model(\n",
    "                input_ids=input_ids.to(DEVICE),\n",
    "                attention_mask=input_att_mask.to(DEVICE),\n",
    "                decoder_attention_mask=target_att_mask.to(DEVICE),\n",
    "                labels=target_ids.to(DEVICE)\n",
    "            ).loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() # accumulate loss\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                tmp_loss = running_loss / 100 # Loss for last 100 steps\n",
    "\n",
    "                print(f\"Loss: {tmp_loss} at STEP: {step}\")\n",
    "                running_loss = 0.\n",
    "\n",
    "            step += 1\n",
    "\n",
    "            # This is a bit of a trick so that we can empty unneded batch from the GPU after each step\n",
    "            input_ids, input_att_mask, target_ids, target_att_mask = [None] * 4\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11a55619-66c8-444a-a928-a8e853ce4760",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH - 0\n",
      "Loss: 0.16089296340942383 at STEP: 0\n",
      "Loss: 0.600663215816021 at STEP: 100\n",
      "Loss: 0.38326781705021856 at STEP: 200\n",
      "Loss: 0.34955278113484384 at STEP: 300\n",
      "Loss: 0.3486653026938438 at STEP: 400\n",
      "Loss: 0.316450661867857 at STEP: 500\n",
      "Loss: 0.31583479553461075 at STEP: 600\n",
      "Loss: 0.3136375516653061 at STEP: 700\n",
      "Loss: 0.30486680924892423 at STEP: 800\n",
      "Loss: 0.2969446086883545 at STEP: 900\n",
      "Loss: 0.3022655549645424 at STEP: 1000\n",
      "Loss: 0.2967348997294903 at STEP: 1100\n",
      "Loss: 0.3076150432229042 at STEP: 1200\n",
      "Loss: 0.2881550267338753 at STEP: 1300\n",
      "Loss: 0.2972696757316589 at STEP: 1400\n",
      "Loss: 0.2856902155280113 at STEP: 1500\n",
      "Loss: 0.2977496628463268 at STEP: 1600\n",
      "Loss: 0.2894183366000652 at STEP: 1700\n",
      "Loss: 0.2760576483607292 at STEP: 1800\n",
      "Loss: 0.2877181653678417 at STEP: 1900\n",
      "Loss: 0.27939183324575423 at STEP: 2000\n",
      "Loss: 0.27606276467442514 at STEP: 2100\n",
      "Loss: 0.2808814299106598 at STEP: 2200\n",
      "Loss: 0.2647849689424038 at STEP: 2300\n",
      "Loss: 0.27302410259842874 at STEP: 2400\n",
      "Loss: 0.26966498762369157 at STEP: 2500\n",
      "Loss: 0.26413708806037905 at STEP: 2600\n",
      "Loss: 0.26618170469999314 at STEP: 2700\n",
      "Loss: 0.24834418281912804 at STEP: 2800\n",
      "Loss: 0.2517653304338455 at STEP: 2900\n",
      "Loss: 0.2382284700870514 at STEP: 3000\n",
      "Loss: 0.22316650740802288 at STEP: 3100\n",
      "Loss: 0.19445221707224847 at STEP: 3200\n",
      "Loss: 0.18176206789910793 at STEP: 3300\n",
      "Loss: 0.1794800714403391 at STEP: 3400\n",
      "Loss: 0.1613110186159611 at STEP: 3500\n",
      "Loss: 0.17620192091912032 at STEP: 3600\n",
      "Loss: 0.18034444823861123 at STEP: 3700\n",
      "Loss: 0.17658417016267777 at STEP: 3800\n",
      "Loss: 0.1840399643778801 at STEP: 3900\n",
      "Loss: 0.177067426815629 at STEP: 4000\n",
      "Loss: 0.17988303929567337 at STEP: 4100\n",
      "Loss: 0.1777712872251868 at STEP: 4200\n",
      "Loss: 0.17668131075799465 at STEP: 4300\n",
      "Loss: 0.1836095366626978 at STEP: 4400\n",
      "Loss: 0.1819648114591837 at STEP: 4500\n",
      "Loss: 0.17453334376215934 at STEP: 4600\n",
      "Loss: 0.17589196875691415 at STEP: 4700\n",
      "Loss: 0.18208932533860206 at STEP: 4800\n",
      "Loss: 0.19119278214871882 at STEP: 4900\n",
      "Loss: 0.16633206762373448 at STEP: 5000\n",
      "Loss: 0.17965547122061254 at STEP: 5100\n",
      "Loss: 0.17850724913179875 at STEP: 5200\n",
      "Loss: 0.18272331923246385 at STEP: 5300\n",
      "Loss: 0.18771169617772102 at STEP: 5400\n",
      "Loss: 0.20250588588416576 at STEP: 5500\n",
      "Loss: 0.1985297540575266 at STEP: 5600\n",
      "Loss: 0.18601813942193984 at STEP: 5700\n",
      "Loss: 0.1697424665093422 at STEP: 5800\n",
      "Loss: 0.18518405333161353 at STEP: 5900\n",
      "Loss: 0.18872819073498248 at STEP: 6000\n",
      "Loss: 0.18663891166448593 at STEP: 6100\n",
      "Loss: 0.19543277494609357 at STEP: 6200\n",
      "Loss: 0.1827017717063427 at STEP: 6300\n",
      "Loss: 0.19233044356107712 at STEP: 6400\n",
      "Loss: 0.18192902132868766 at STEP: 6500\n",
      "Loss: 0.19230336673557757 at STEP: 6600\n",
      "Loss: 0.1949261199682951 at STEP: 6700\n",
      "Loss: 0.1945831822603941 at STEP: 6800\n",
      "Loss: 0.18843394309282302 at STEP: 6900\n",
      "Loss: 0.20545109294354916 at STEP: 7000\n",
      "Loss: 0.19157283663749694 at STEP: 7100\n",
      "Loss: 0.20278707601130008 at STEP: 7200\n",
      "Loss: 0.2017399910837412 at STEP: 7300\n",
      "Loss: 0.2032010928541422 at STEP: 7400\n",
      "Loss: 0.20813320353627204 at STEP: 7500\n",
      "Loss: 0.20220274277031422 at STEP: 7600\n",
      "Loss: 0.21600778348743915 at STEP: 7700\n",
      "Loss: 0.20980593256652355 at STEP: 7800\n",
      "Loss: 0.20893192917108536 at STEP: 7900\n",
      "Loss: 0.2079140417277813 at STEP: 8000\n",
      "Loss: 0.2126495111733675 at STEP: 8100\n",
      "EPOCH - 1\n",
      "Loss: 0.2089279678463936 at STEP: 8200\n",
      "Loss: 0.20249502032995223 at STEP: 8300\n",
      "Loss: 0.19840037547051906 at STEP: 8400\n",
      "Loss: 0.18676567807793618 at STEP: 8500\n",
      "Loss: 0.19727619156241416 at STEP: 8600\n",
      "Loss: 0.19837746381759644 at STEP: 8700\n",
      "Loss: 0.18685421250760556 at STEP: 8800\n",
      "Loss: 0.19545482322573662 at STEP: 8900\n",
      "Loss: 0.19126722007989883 at STEP: 9000\n",
      "Loss: 0.18402662321925164 at STEP: 9100\n",
      "Loss: 0.19182001531124115 at STEP: 9200\n",
      "Loss: 0.19657584853470325 at STEP: 9300\n",
      "Loss: 0.20365517802536487 at STEP: 9400\n",
      "Loss: 0.20639847673475742 at STEP: 9500\n",
      "Loss: 0.19304314866662026 at STEP: 9600\n",
      "Loss: 0.2023609084635973 at STEP: 9700\n",
      "Loss: 0.19357006005942823 at STEP: 9800\n",
      "Loss: 0.2044592310488224 at STEP: 9900\n",
      "Loss: 0.20622441850602627 at STEP: 10000\n",
      "Loss: 0.2087198033183813 at STEP: 10100\n",
      "Loss: 0.1964183697849512 at STEP: 10200\n",
      "Loss: 0.20187017396092416 at STEP: 10300\n",
      "Loss: 0.22451193191111088 at STEP: 10400\n",
      "Loss: 0.20493963189423084 at STEP: 10500\n",
      "Loss: 0.21513035714626313 at STEP: 10600\n",
      "Loss: 0.21457674309611321 at STEP: 10700\n",
      "Loss: 0.22064668625593187 at STEP: 10800\n",
      "Loss: 0.20910817332565784 at STEP: 10900\n",
      "Loss: 0.21518916323781012 at STEP: 11000\n",
      "Loss: 0.21784377209842204 at STEP: 11100\n",
      "Loss: 0.22462265342473983 at STEP: 11200\n",
      "Loss: 0.22355912275612355 at STEP: 11300\n",
      "Loss: 0.21621532492339612 at STEP: 11400\n",
      "Loss: 0.20667496874928473 at STEP: 11500\n",
      "Loss: 0.19440532699227334 at STEP: 11600\n",
      "Loss: 0.20281508013606073 at STEP: 11700\n",
      "Loss: 0.19794171318411827 at STEP: 11800\n",
      "Loss: 0.20317998416721822 at STEP: 11900\n",
      "Loss: 0.20924212388694285 at STEP: 12000\n",
      "Loss: 0.21895334638655187 at STEP: 12100\n",
      "Loss: 0.20748834557831286 at STEP: 12200\n",
      "Loss: 0.20936763405799866 at STEP: 12300\n",
      "Loss: 0.2107153230905533 at STEP: 12400\n",
      "Loss: 0.1967036782205105 at STEP: 12500\n",
      "Loss: 0.2094141188263893 at STEP: 12600\n",
      "Loss: 0.2023110917955637 at STEP: 12700\n",
      "Loss: 0.2144873347133398 at STEP: 12800\n",
      "Loss: 0.20140838742256165 at STEP: 12900\n",
      "Loss: 0.20968728445470333 at STEP: 13000\n",
      "Loss: 0.1887036830931902 at STEP: 13100\n",
      "Loss: 0.1939937788248062 at STEP: 13200\n",
      "Loss: 0.19374072894454003 at STEP: 13300\n",
      "Loss: 0.2041893997043371 at STEP: 13400\n",
      "Loss: 0.19973212398588658 at STEP: 13500\n",
      "Loss: 0.2050137384235859 at STEP: 13600\n",
      "Loss: 0.19978476084768773 at STEP: 13700\n",
      "Loss: 0.19611515842378138 at STEP: 13800\n",
      "Loss: 0.1897152938693762 at STEP: 13900\n",
      "Loss: 0.18860777668654918 at STEP: 14000\n",
      "Loss: 0.19752791196107863 at STEP: 14100\n",
      "Loss: 0.21671471983194351 at STEP: 14200\n",
      "Loss: 0.2003290931880474 at STEP: 14300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfine_tune_t5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Run the fine tunning\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 25\u001b[0m, in \u001b[0;36mfine_tune_t5\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m model(\n\u001b[1;32m     19\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mto(DEVICE),\n\u001b[1;32m     20\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39minput_att_mask\u001b[38;5;241m.\u001b[39mto(DEVICE),\n\u001b[1;32m     21\u001b[0m     decoder_attention_mask\u001b[38;5;241m=\u001b[39mtarget_att_mask\u001b[38;5;241m.\u001b[39mto(DEVICE),\n\u001b[1;32m     22\u001b[0m     labels\u001b[38;5;241m=\u001b[39mtarget_ids\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     23\u001b[0m )\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     28\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;66;03m# accumulate loss\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fine_tune_t5(epochs=5) # Run the fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7691bef9-6180-4d35-8eaf-e40e86b4de30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./fine-tuned-t5-small-squad-multi-pass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589b0c2b-d3a1-4392-a115-21348d7d188e",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1752338-11a1-48de-8f73-f389db9b0036",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset SQuAD version: v2.0\n",
      "Loading paragraph: Normans\n",
      "Loading paragraph: Computational_complexity_theory\n",
      "Loading paragraph: Southern_California\n",
      "Loading paragraph: Sky_(United_Kingdom)\n",
      "Loading paragraph: Victoria_(Australia)\n",
      "Loading paragraph: Huguenot\n",
      "Loading paragraph: Steam_engine\n",
      "Loading paragraph: Oxygen\n",
      "Loading paragraph: 1973_oil_crisis\n",
      "Loading paragraph: European_Union_law\n",
      "Loading paragraph: Amazon_rainforest\n",
      "Loading paragraph: Ctenophora\n",
      "Loading paragraph: Fresno,_California\n",
      "Loading paragraph: Packet_switching\n",
      "Loading paragraph: Black_Death\n",
      "Loading paragraph: Geology\n",
      "Loading paragraph: Pharmacy\n",
      "Loading paragraph: Civil_disobedience\n",
      "Loading paragraph: Construction\n",
      "Loading paragraph: Private_school\n",
      "Loading paragraph: Harvard_University\n",
      "Loading paragraph: Jacksonville,_Florida\n",
      "Loading paragraph: Economic_inequality\n",
      "Loading paragraph: University_of_Chicago\n",
      "Loading paragraph: Yuan_dynasty\n",
      "Loading paragraph: Immune_system\n",
      "Loading paragraph: Intergovernmental_Panel_on_Climate_Change\n",
      "Loading paragraph: Prime_number\n",
      "Loading paragraph: Rhine\n",
      "Loading paragraph: Scottish_Parliament\n",
      "Loading paragraph: Islamism\n",
      "Loading paragraph: Imperialism\n",
      "Loading paragraph: Warsaw\n",
      "Loading paragraph: French_and_Indian_War\n",
      "Loading paragraph: Force\n"
     ]
    }
   ],
   "source": [
    "ds_eval: SQuADDataset = load_dataset_and_preprocess(\"./dev-v2.0.json\")\n",
    "eval_input = ds_eval.tokenize_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9676896c-3e6f-4af9-baaf-55d19318aa90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_for_evaluation = TensorDataset(eval_input[\"input_ids\"])\n",
    "evaluation_dataloader = DataLoader(data_for_evaluation, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "578d25c1-531e-45f6-81c3-2e16b4e35463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model: str, dataloader: str, out_file: str, question_ids: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    We are not running eval in the model as it is usually done, we will record the inference\n",
    "    results with the .json file and use official script to compare the models.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for data in dataloader:\n",
    "        batch_of_inputs = data[0]\n",
    "        \n",
    "        outputs = model.generate(batch_of_inputs.to(DEVICE))\n",
    "        \n",
    "        results.extend(outputs)\n",
    "        \n",
    "        # We will dereference values held in outputs to free cuda memory\n",
    "        outputs = None\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"Done with inference, decoding answers and generating output file at {out_file}\")\n",
    "    \n",
    "    out_file_contents = {}\n",
    "\n",
    "    for question_id, generated_answer in zip(question_ids, results):\n",
    "        out_file_contents[question_id] = tokenizer.decode(generated_answer, skip_special_tokens=True)\n",
    "        \n",
    "    file_pointer = open(out_file, \"w\")\n",
    "    \n",
    "    json.dump(out_file_contents, file_pointer)\n",
    "    file_pointer.close()\n",
    "    \n",
    "    print(\"You can check the file now!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f6e67-7241-4f8c-8211-c865027543d7",
   "metadata": {},
   "source": [
    "## Evaluation before finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7a29fdc-0f30-421d-9a7a-b7bb8d3c2af3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_model_used = \"google-t5/t5-small\"\n",
    "\n",
    "# We want to map immidiatley the model onto the GPU\n",
    "baseline_model = T5ForConditionalGeneration.from_pretrained(pretrained_model_used, device_map=DEVICE, torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4debaa95-ca30-4842-85a4-62d3201d97f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with inference, decoding answers and generating output file at baseline.json\n",
      "You can check the file now!\n"
     ]
    }
   ],
   "source": [
    "evaluate(model=baseline_model, dataloader=evaluation_dataloader, out_file=\"baseline.json\", question_ids=ds_eval.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346391db-79e4-4cf7-9fc9-164891d08d9f",
   "metadata": {},
   "source": [
    "## Evaluation after finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6fc2e1c-435b-478b-a75e-b9e32b9a8f9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_model_used = \"google-t5/t5-small\"\n",
    "\n",
    "# We want to map immidiatley the model onto the GPU\n",
    "fine_tuned_model = T5ForConditionalGeneration.from_pretrained(\"./fine-tuned-t5-small-squad-multi-pass\", device_map=DEVICE, torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a53a49da-a955-4a2d-bcba-1127cf1d3202",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with inference, decoding answers and generating output file at finetuned.json\n",
      "You can check the file now!\n"
     ]
    }
   ],
   "source": [
    "evaluate(model=fine_tuned_model, dataloader=evaluation_dataloader, out_file=\"finetuned.json\", question_ids=ds_eval.ids)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu113.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu113:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
